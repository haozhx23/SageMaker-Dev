{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c37c63b1-f665-4008-9369-45782fc02d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "sagemaker_default_bucket = sess.default_bucket()\n",
    "\n",
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = sess.boto_session.region_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5125b711-3bf9-4938-8c6f-b4898412ef84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpioptions = \"-x NCCL_DEBUG=WARN -x SMDEBUG_LOG_LEVEL=ERROR \"\n",
    "mpioptions += \"-x SMP_DISABLE_D2D=1 -x SMP_D2D_GPU_BUFFER_SIZE_BYTES=1 -x SMP_NCCL_THROTTLE_LIMIT=1 \"\n",
    "mpioptions += \"-x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63ae28a6-4fa5-4a30-a103-05b7968e1859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "image_uri = '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.0.0-gpu-py310-cu118-ubuntu20.04-sagemaker'\n",
    "# image_uri = '763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.13.1-gpu-py39-cu117-ubuntu20.04-sagemaker'\n",
    "# image_uri = '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:1.13.1-transformers4.26.0-gpu-py39-cu117-ubuntu20.04'\n",
    "\n",
    "cfg = OmegaConf.load('smp_llama_7b_zh_instruct_coig.yaml')\n",
    "\n",
    "est = PyTorch(role=role,\n",
    "            entry_point='smp_trainer_base_ds_mul_aws.py',\n",
    "            source_dir='./',\n",
    "            base_job_name='panda-llm-smp-job',\n",
    "            instance_count=1,\n",
    "            instance_type='ml.p4d.24xlarge',\n",
    "            image_uri=image_uri,\n",
    "            # framework_version='1.13.1',\n",
    "            # py_version='py39',\n",
    "            distribution={\n",
    "                \"mpi\": {\"enabled\": True,\n",
    "                        \"processes_per_host\": 8,\n",
    "                        \"custom_mpi_options\": mpioptions,\n",
    "                       },\n",
    "                \"smdistributed\": {\n",
    "                        \"modelparallel\": {\n",
    "                            \"enabled\": True,\n",
    "                            \"parameters\": dict(cfg.smp_init_params),\n",
    "                        }\n",
    "                    }\n",
    "            },\n",
    "            max_run=3600*24*2, # 训练任务存续的时间上限\n",
    "            keep_alive_period_in_seconds=3600,\n",
    "            disable_profiler=True,\n",
    "            debugger_hook_config=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a8e65-bcdf-42f9-878c-8419c1da7ffe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: panda-llm-job-2023-05-26-07-50-10-248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-05-26 07:50:13 Starting - Starting the training job..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:23,135 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:23,194 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:23,202 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:23,203 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:24,662 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting wandb (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 37.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 57.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 72.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting sentencepiece (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 96.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.28.1 (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 99.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.3.0-py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 16.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch==2.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting hydra-core (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 154.5/154.5 kB 32.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting fairscale (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading fairscale-0.4.13.tar.gz (266 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 266.3/266.3 kB 47.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling backend dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 5)) (3.12.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.28.1->-r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 224.5/224.5 kB 42.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 5)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 5)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 5)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers==4.28.1->-r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading regex-2023.5.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 769.7/769.7 kB 72.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 5)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.1->-r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 99.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 5)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->-r requirements.txt (line 7)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->-r requirements.txt (line 7)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->-r requirements.txt (line 7)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0->-r requirements.txt (line 7)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 1)) (8.1.3)\u001b[0m\n",
      "\u001b[34mCollecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.31-py3-none-any.whl (184 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 184.3/184.3 kB 37.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 1)) (5.9.5)\u001b[0m\n",
      "\u001b[34mCollecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading sentry_sdk-1.24.0-py2.py3-none-any.whl (206 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 206.5/206.5 kB 37.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting pathtools (from wandb->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading pathtools-0.1.2.tar.gz (11 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting setproctitle (from wandb->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 1)) (65.6.3)\u001b[0m\n",
      "\u001b[34mCollecting appdirs>=1.4.3 (from wandb->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 1)) (3.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 2)) (1.2.0)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4 (from tensorboard->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 25.9 MB/s eta 0:00:00\u001b[0m\n",
      "\n",
      "2023-05-26 07:50:22 Downloading - Downloading input data\n",
      "2023-05-26 07:50:22 Training - Training image download completed. Training in progress.\u001b[34mCollecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading grpcio-1.54.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 102.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3 (from tensorboard->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.19.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 39.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.4.3-py3-none-any.whl (93 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.9/93.9 kB 18.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 108.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 3)) (2.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 3)) (0.40.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft->-r requirements.txt (line 6)) (0.19.0)\u001b[0m\n",
      "\u001b[34mCollecting omegaconf<2.4,>=2.2 (from hydra-core->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 21.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting antlr4-python3-runtime==4.9.* (from hydra-core->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 30.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.10-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 15.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 42.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (1.26.15)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1->-r requirements.txt (line 5)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.1->-r requirements.txt (line 5)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.1->-r requirements.txt (line 5)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.28.1->-r requirements.txt (line 5)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 3)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.0->-r requirements.txt (line 7)) (1.3.0)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 32.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: antlr4-python3-runtime, fairscale, pathtools\u001b[0m\n",
      "\u001b[34mBuilding wheel for antlr4-python3-runtime (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=33c27a1a2f90e82f881a358e73220a8ac2390c1773d955674b9aa6bedf892b4a\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\u001b[0m\n",
      "\u001b[34mBuilding wheel for fairscale (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for fairscale (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=609ab3e197ede8aecde9fbac2a5026b01619083a9f926933e91f45d21487f7bb\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\u001b[0m\n",
      "\u001b[34mBuilding wheel for pathtools (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for pathtools (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=2bc415987742600c6d7cde61f28d41e41d8560922fd1073bd2c5561af128050c\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\u001b[0m\n",
      "\u001b[34mSuccessfully built antlr4-python3-runtime fairscale pathtools\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tokenizers, sentencepiece, pathtools, appdirs, antlr4-python3-runtime, tensorboard-data-server, smmap, setproctitle, sentry-sdk, regex, pyasn1-modules, omegaconf, oauthlib, markdown, grpcio, docker-pycreds, cachetools, absl-py, requests-oauthlib, nltk, hydra-core, huggingface-hub, google-auth, gitdb, transformers, google-auth-oauthlib, GitPython, fairscale, wandb, tensorboard, peft\u001b[0m\n",
      "\u001b[34mSuccessfully installed GitPython-3.1.31 absl-py-1.4.0 antlr4-python3-runtime-4.9.3 appdirs-1.4.4 cachetools-5.3.0 docker-pycreds-0.4.0 fairscale-0.4.13 gitdb-4.0.10 google-auth-2.19.0 google-auth-oauthlib-1.0.0 grpcio-1.54.2 huggingface-hub-0.14.1 hydra-core-1.3.2 markdown-3.4.3 nltk-3.8.1 oauthlib-3.2.2 omegaconf-2.3.0 pathtools-0.1.2 peft-0.3.0 pyasn1-modules-0.3.0 regex-2023.5.5 requests-oauthlib-1.3.1 sentencepiece-0.1.99 sentry-sdk-1.24.0 setproctitle-1.3.2 smmap-5.0.0 tensorboard-2.13.0 tensorboard-data-server-0.7.0 tokenizers-0.13.3 transformers-4.28.1 wandb-0.15.3\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:42,950 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:42,950 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:43,012 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:43,079 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:43,087 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:43,087 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:43,087 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:43,087 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1'] Hosts: ['algo-1:8'] process_per_hosts: 8 num_processes: 8\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:43,088 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:43,146 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:43,155 sagemaker-training-toolkit INFO     PyTorch version is 2.0.0\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:43,213 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:43,221 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": false,\n",
      "        \"sagemaker_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"-x NCCL_DEBUG=WARN -x SMDEBUG_LOG_LEVEL=ERROR -x SMP_DISABLE_D2D=1 -x SMP_D2D_GPU_BUFFER_SIZE_BYTES=1 -x SMP_NCCL_THROTTLE_LIMIT=1 -x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1\",\n",
      "        \"sagemaker_mpi_enabled\": true,\n",
      "        \"sagemaker_mpi_num_of_processes_per_host\": 8\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train123\": \"/opt/ml/input/data/train123\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"mp_parameters\": {\n",
      "            \"ddp\": true,\n",
      "            \"tensor_parallel_degree\": 1,\n",
      "            \"partitions\": 8,\n",
      "            \"fp16\": false,\n",
      "            \"bf16\": true,\n",
      "            \"activation_loading_horizon\": 4,\n",
      "            \"skip_tracing\": true,\n",
      "            \"delayed_parameter_initialization\": true,\n",
      "            \"prescaled_batch\": false,\n",
      "            \"microbatches\": 2,\n",
      "            \"active_microbatches\": 2,\n",
      "            \"shard_optimizer_state\": true,\n",
      "            \"optimize\": \"memory\",\n",
      "            \"auto_partition\": true,\n",
      "            \"default_partition\": 0,\n",
      "            \"offload_activations\": true\n",
      "        }\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train123\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": true,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"panda-llm-job-2023-05-26-07-50-10-248\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-633205212955/panda-llm-job-2023-05-26-07-50-10-248/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"smp_trainer_base_ds_mul_aws\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"smp_trainer_base_ds_mul_aws.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"mp_parameters\":{\"activation_loading_horizon\":4,\"active_microbatches\":2,\"auto_partition\":true,\"bf16\":true,\"ddp\":true,\"default_partition\":0,\"delayed_parameter_initialization\":true,\"fp16\":false,\"microbatches\":2,\"offload_activations\":true,\"optimize\":\"memory\",\"partitions\":8,\"prescaled_batch\":false,\"shard_optimizer_state\":true,\"skip_tracing\":true,\"tensor_parallel_degree\":1}}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=smp_trainer_base_ds_mul_aws.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p4d.24xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-x NCCL_DEBUG=WARN -x SMDEBUG_LOG_LEVEL=ERROR -x SMP_DISABLE_D2D=1 -x SMP_D2D_GPU_BUFFER_SIZE_BYTES=1 -x SMP_NCCL_THROTTLE_LIMIT=1 -x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train123\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train123\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p4d.24xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=smp_trainer_base_ds_mul_aws\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-633205212955/panda-llm-job-2023-05-26-07-50-10-248/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p4d.24xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-x NCCL_DEBUG=WARN -x SMDEBUG_LOG_LEVEL=ERROR -x SMP_DISABLE_D2D=1 -x SMP_D2D_GPU_BUFFER_SIZE_BYTES=1 -x SMP_NCCL_THROTTLE_LIMIT=1 -x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8},\"channel_input_dirs\":{\"train123\":\"/opt/ml/input/data/train123\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p4d.24xlarge\",\"distribution_hosts\":[\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"mp_parameters\":{\"activation_loading_horizon\":4,\"active_microbatches\":2,\"auto_partition\":true,\"bf16\":true,\"ddp\":true,\"default_partition\":0,\"delayed_parameter_initialization\":true,\"fp16\":false,\"microbatches\":2,\"offload_activations\":true,\"optimize\":\"memory\",\"partitions\":8,\"prescaled_batch\":false,\"shard_optimizer_state\":true,\"skip_tracing\":true,\"tensor_parallel_degree\":1}},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train123\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"panda-llm-job-2023-05-26-07-50-10-248\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-633205212955/panda-llm-job-2023-05-26-07-50-10-248/source/sourcedir.tar.gz\",\"module_name\":\"smp_trainer_base_ds_mul_aws\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"smp_trainer_base_ds_mul_aws.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--mp_parameters\",\"activation_loading_horizon=4,active_microbatches=2,auto_partition=True,bf16=True,ddp=True,default_partition=0,delayed_parameter_initialization=True,fp16=False,microbatches=2,offload_activations=True,optimize=memory,partitions=8,prescaled_batch=False,shard_optimizer_state=True,skip_tracing=True,tensor_parallel_degree=1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN123=/opt/ml/input/data/train123\u001b[0m\n",
      "\u001b[34mSM_HP_MP_PARAMETERS={\"activation_loading_horizon\":4,\"active_microbatches\":2,\"auto_partition\":true,\"bf16\":true,\"ddp\":true,\"default_partition\":0,\"delayed_parameter_initialization\":true,\"fp16\":false,\"microbatches\":2,\"offload_activations\":true,\"optimize\":\"memory\",\"partitions\":8,\"prescaled_batch\":false,\"shard_optimizer_state\":true,\"skip_tracing\":true,\"tensor_parallel_degree\":1}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:8 -np 8 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/opt/conda/lib/python3.10/site-packages/gethostname.cpython-310-x86_64-linux-gnu.so -x NCCL_DEBUG=WARN -x SMDEBUG_LOG_LEVEL=ERROR -x SMP_DISABLE_D2D=1 -x SMP_D2D_GPU_BUFFER_SIZE_BYTES=1 -x SMP_NCCL_THROTTLE_LIMIT=1 -x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x FI_PROVIDER=efa -x NCCL_PROTO=simple -x FI_EFA_USE_DEVICE_RDMA=1 -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_CURRENT_INSTANCE_TYPE -x SM_CURRENT_INSTANCE_GROUP -x SM_CURRENT_INSTANCE_GROUP_HOSTS -x SM_INSTANCE_GROUPS -x SM_INSTANCE_GROUPS_DICT -x SM_DISTRIBUTION_INSTANCE_GROUPS -x SM_IS_HETERO -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_NUM_NEURONS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_TRAIN123 -x SM_HP_MP_PARAMETERS -x PYTHONPATH -x NCCL_PROTO=simple -x NCCL_ALGO=ring smddpmprun -i ml.p4d.24xlarge --allow-bypass /opt/conda/bin/python3.10 -m mpi4py smp_trainer_base_ds_mul_aws.py --mp_parameters activation_loading_horizon=4,active_microbatches=2,auto_partition=True,bf16=True,ddp=True,default_partition=0,delayed_parameter_initialization=True,fp16=False,microbatches=2,offload_activations=True,optimize=memory,partitions=8,prescaled_batch=False,shard_optimizer_state=True,skip_tracing=True,tensor_parallel_degree=1\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:43,281 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m[2023-05-26 07:50:44.676: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-05-26 07:50:44,689 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mData for JOB [41095,1] offset 0 Total slots allocated 8\n",
      " ========================   JOB MAP   ========================\n",
      " Data for node: algo-1#011Num slots: 8#011Max slots: 0#011Num procs: 8\n",
      " #011Process OMPI jobid: [41095,1] App: 0 Process rank: 0 Bound: N/A\n",
      " #011Process OMPI jobid: [41095,1] App: 0 Process rank: 1 Bound: N/A\n",
      " #011Process OMPI jobid: [41095,1] App: 0 Process rank: 2 Bound: N/A\n",
      " #011Process OMPI jobid: [41095,1] App: 0 Process rank: 3 Bound: N/A\n",
      " #011Process OMPI jobid: [41095,1] App: 0 Process rank: 4 Bound: N/A\n",
      " #011Process OMPI jobid: [41095,1] App: 0 Process rank: 5 Bound: N/A\n",
      " #011Process OMPI jobid: [41095,1] App: 0 Process rank: 6 Bound: N/A\n",
      " #011Process OMPI jobid: [41095,1] App: 0 Process rank: 7 Bound: N/A\n",
      " =============================================================\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-05-26 07:50:47.791: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-05-26 07:50:47.791: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-05-26 07:50:47.791: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:47.841: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-05-26 07:50:47.841: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-05-26 07:50:47.841: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-05-26 07:50:47.841: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-05-26 07:50:47.841: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.28.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-05-26 07:50:53.251: W smdistributed/modelparallel/backend/core.py:423] smddp backend does not support training on single node. Falling back to nccl backend.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-05-26 07:50:53.251: W smdistributed/modelparallel/backend/core.py:423] smddp backend does not support training on single node. Falling back to nccl backend.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-05-26 07:50:53.251: W smdistributed/modelparallel/backend/core.py:423] smddp backend does not support training on single node. Falling back to nccl backend.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-05-26 07:50:53.251: W smdistributed/modelparallel/backend/core.py:423] smddp backend does not support training on single node. Falling back to nccl backend.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-05-26 07:50:53.251: W smdistributed/modelparallel/backend/core.py:423] smddp backend does not support training on single node. Falling back to nccl backend.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-05-26 07:50:53.251: W smdistributed/modelparallel/backend/core.py:423] smddp backend does not support training on single node. Falling back to nccl backend.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.251: W smdistributed/modelparallel/backend/core.py:423] smddp backend does not support training on single node. Falling back to nccl backend.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-05-26 07:50:53.251: W smdistributed/modelparallel/backend/core.py:423] smddp backend does not support training on single node. Falling back to nccl backend.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.252: I smdistributed/modelparallel/backend/core.py:481] [smddp] SMDATAPARALLEL_DEVICE_NAME is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.252: I smdistributed/modelparallel/backend/core.py:481] [smddp] SAGEMAKER_INSTANCE_TYPE is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-05-26 07:50:53.252: I smdistributed/modelparallel/backend/core.py:481] [smddp] SMDATAPARALLEL_DEVICE_NAME is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-05-26 07:50:53.252: I smdistributed/modelparallel/backend/core.py:481] [smddp] SMDATAPARALLEL_DEVICE_NAME is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/torch/state_mod.py:100] [0] Initializing torch distributed process groups with nccl backend\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-05-26 07:50:53.252: I smdistributed/modelparallel/backend/core.py:481] [smddp] SMDATAPARALLEL_DEVICE_NAME is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/backend/core.py:481] [smddp] SMDATAPARALLEL_DEVICE_NAME is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/backend/core.py:481] [smddp] SAGEMAKER_INSTANCE_TYPE is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/backend/core.py:481] [smddp] SAGEMAKER_INSTANCE_TYPE is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/backend/core.py:481] [smddp] SMDATAPARALLEL_DEVICE_NAME is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/backend/core.py:481] [smddp] SAGEMAKER_INSTANCE_TYPE is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/backend/core.py:481] [smddp] SMDATAPARALLEL_DEVICE_NAME is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/torch/state_mod.py:100] [4] Initializing torch distributed process groups with nccl backend\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/torch/state_mod.py:100] [3] Initializing torch distributed process groups with nccl backend\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/backend/core.py:481] [smddp] SAGEMAKER_INSTANCE_TYPE is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/backend/core.py:481] [smddp] SAGEMAKER_INSTANCE_TYPE is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/torch/state_mod.py:100] [1] Initializing torch distributed process groups with nccl backend\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/backend/core.py:481] [smddp] SAGEMAKER_INSTANCE_TYPE is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/torch/state_mod.py:100] [2] Initializing torch distributed process groups with nccl backend\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/torch/state_mod.py:100] [7] Initializing torch distributed process groups with nccl backend\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/torch/state_mod.py:100] [5] Initializing torch distributed process groups with nccl backend\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/backend/core.py:481] [smddp] SMDATAPARALLEL_DEVICE_NAME is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/backend/core.py:481] [smddp] SAGEMAKER_INSTANCE_TYPE is defined in os.environ: True.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-05-26 07:50:53.253: I smdistributed/modelparallel/torch/state_mod.py:100] [6] Initializing torch distributed process groups with nccl backend\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:3 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:3 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:3 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:3 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:3 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:3 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:3 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:4 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:4 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:4 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:4 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:4 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:4 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:4 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:5 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:5 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:5 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:5 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:5 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:5 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:5 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:6 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:6 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:6 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:6 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:6 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:6 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:6 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:7 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:7 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:7 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:7 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:7 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:7 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:7 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:8 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:8 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:8 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:8 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:8 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:8 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:8 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:8 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:9 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:9 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:9 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:9 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:9 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:9 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:9 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:9 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:10 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:10 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:10 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:10 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:10 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:10 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:10 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:10 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:11 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:11 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:11 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:11 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:11 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:11 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:11 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:11 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:12 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:12 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:12 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:12 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:12 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:12 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:12 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:12 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:13 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:13 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:13 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:13 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:13 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:13 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:13 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:13 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:14 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:14 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:14 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:14 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:14 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:14 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:14 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:14 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:15 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:15 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:15 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:15 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:15 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:15 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:15 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:15 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:16 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:16 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:16 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:16 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:16 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:16 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:16 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:16 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:17 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:17 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:17 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:17 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:17 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:17 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:17 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:17 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:18 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:18 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:18 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:18 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:18 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:18 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:18 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:18 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:19 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:19 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:19 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:19 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:19 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:19 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:19 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:19 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:20 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:20 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:20 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:20 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:20 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:20 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:20 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:20 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:21 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:21 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:21 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:21 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:21 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:21 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:21 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:21 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:22 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:22 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:22 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:22 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:22 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:22 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:22 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:22 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:23 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:23 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:23 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:23 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:23 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:23 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:23 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:23 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:24 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:24 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:24 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:24 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:24 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:24 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:24 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:24 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:25 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:25 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:25 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:25 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:25 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:25 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:25 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:25 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:26 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:26 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:26 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:26 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:26 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:26 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:26 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:26 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:27 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:27 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-05-26 07:50:53.521: I smdistributed/modelparallel/torch/state_mod.py:163] [5] Finished initializing torch distributed process groups. pp_rank: 5, tp_rank: 0, dp_rank: 0, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-05-26 07:50:53.521: I smdistributed/modelparallel/torch/state_mod.py:163] [6] Finished initializing torch distributed process groups. pp_rank: 6, tp_rank: 0, dp_rank: 0, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:27 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:27 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:27 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:27 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:27 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:27 with 8 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-05-26 07:50:53.531: I smdistributed/modelparallel/torch/state_mod.py:163] [2] Finished initializing torch distributed process groups. pp_rank: 2, tp_rank: 0, dp_rank: 0, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.531: I smdistributed/modelparallel/torch/state_mod.py:163] [0] Finished initializing torch distributed process groups. pp_rank: 0, tp_rank: 0, dp_rank: 0, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-05-26 07:50:53.531: I smdistributed/modelparallel/torch/state_mod.py:163] [1] Finished initializing torch distributed process groups. pp_rank: 1, tp_rank: 0, dp_rank: 0, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-05-26 07:50:53.531: I smdistributed/modelparallel/torch/state_mod.py:163] [3] Finished initializing torch distributed process groups. pp_rank: 3, tp_rank: 0, dp_rank: 0, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-05-26 07:50:53.531: I smdistributed/modelparallel/torch/state_mod.py:163] [4] Finished initializing torch distributed process groups. pp_rank: 4, tp_rank: 0, dp_rank: 0, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-05-26 07:50:53.531: I smdistributed/modelparallel/torch/state_mod.py:163] [7] Finished initializing torch distributed process groups. pp_rank: 7, tp_rank: 0, dp_rank: 0, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.531: I smdistributed/modelparallel/torch/throttler.py:37] Using NCCL throttle limit of 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.531: I smdistributed/modelparallel/backend/config.py:314] Configuration parameters:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.531: I smdistributed/modelparallel/backend/config.py:317]   activation_loading_horizon: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   active_microbatches: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   auto_partition: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   bf16: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   contiguous: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   ddp: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   ddp_dist_backend: auto\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   ddp_port: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   default_partition: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   delayed_parameter_initialization: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   fp16: False\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   fp16_params: False\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   horovod: False\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   memory_weight: 0.8\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   microbatches: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   offload_activations: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   optimize: memory\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   pipeline: interleaved\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.532: I smdistributed/modelparallel/backend/config.py:317]   pipeline_parallel_degree: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   placement_strategy: cluster\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   predefined_hooks: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   prescaled_batch: False\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   sdp_gradient_clipping: 1.0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   sdp_hierarchical_allgather: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   sdp_max_live_parameters: 1000000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   sdp_param_persistence_threshold: 1000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   sdp_reduce_bucket_size: 500000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   shard_optimizer_state: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   sharded_data_parallel_degree: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   skip_tracing: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   tensor_parallel_degree: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: I smdistributed/modelparallel/backend/config.py:317]   tensor_parallel_seed: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.533: W smdistributed/modelparallel/backend/config.py:323] WARNING: \"fp16_params\" is a deprecated config key, please use \"fp16\" instead\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-05-26 07:50:53.958: W smdistributed/modelparallel/torch/__init__.py:115] SageMaker model parallelism is initialized already. Ignoring the smp.init() call.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-05-26 07:50:53.958: W smdistributed/modelparallel/torch/__init__.py:115] SageMaker model parallelism is initialized already. Ignoring the smp.init() call.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-05-26 07:50:53.958: W smdistributed/modelparallel/torch/__init__.py:115] SageMaker model parallelism is initialized already. Ignoring the smp.init() call.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-05-26 07:50:53.958: W smdistributed/modelparallel/torch/__init__.py:115] SageMaker model parallelism is initialized already. Ignoring the smp.init() call.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:50:53.958: W smdistributed/modelparallel/torch/__init__.py:115] SageMaker model parallelism is initialized already. Ignoring the smp.init() call.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-05-26 07:50:53.958: W smdistributed/modelparallel/torch/__init__.py:115] SageMaker model parallelism is initialized already. Ignoring the smp.init() call.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-05-26 07:50:53.958: W smdistributed/modelparallel/torch/__init__.py:115] SageMaker model parallelism is initialized already. Ignoring the smp.init() call.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-05-26 07:50:53.984: W smdistributed/modelparallel/torch/__init__.py:115] SageMaker model parallelism is initialized already. Ignoring the smp.init() call.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/generation_config.json /tmp/llama_pretrain/generation_config.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model.bin.index.json /tmp/llama_pretrain/pytorch_model.bin.index.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/special_tokens_map.json /tmp/llama_pretrain/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/tokenizer_config.json /tmp/llama_pretrain/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/config.json /tmp/llama_pretrain/config.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/tokenizer.model /tmp/llama_pretrain/tokenizer.model\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00006-of-00033.bin /tmp/llama_pretrain/pytorch_model-00006-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00029-of-00033.bin /tmp/llama_pretrain/pytorch_model-00029-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00023-of-00033.bin /tmp/llama_pretrain/pytorch_model-00023-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00011-of-00033.bin /tmp/llama_pretrain/pytorch_model-00011-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00024-of-00033.bin /tmp/llama_pretrain/pytorch_model-00024-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00021-of-00033.bin /tmp/llama_pretrain/pytorch_model-00021-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00018-of-00033.bin /tmp/llama_pretrain/pytorch_model-00018-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00025-of-00033.bin /tmp/llama_pretrain/pytorch_model-00025-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00028-of-00033.bin /tmp/llama_pretrain/pytorch_model-00028-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00020-of-00033.bin /tmp/llama_pretrain/pytorch_model-00020-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00015-of-00033.bin /tmp/llama_pretrain/pytorch_model-00015-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00008-of-00033.bin /tmp/llama_pretrain/pytorch_model-00008-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00001-of-00033.bin /tmp/llama_pretrain/pytorch_model-00001-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00027-of-00033.bin /tmp/llama_pretrain/pytorch_model-00027-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00004-of-00033.bin /tmp/llama_pretrain/pytorch_model-00004-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00014-of-00033.bin /tmp/llama_pretrain/pytorch_model-00014-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00007-of-00033.bin /tmp/llama_pretrain/pytorch_model-00007-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00003-of-00033.bin /tmp/llama_pretrain/pytorch_model-00003-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00031-of-00033.bin /tmp/llama_pretrain/pytorch_model-00031-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00016-of-00033.bin /tmp/llama_pretrain/pytorch_model-00016-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00013-of-00033.bin /tmp/llama_pretrain/pytorch_model-00013-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00026-of-00033.bin /tmp/llama_pretrain/pytorch_model-00026-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00032-of-00033.bin /tmp/llama_pretrain/pytorch_model-00032-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00030-of-00033.bin /tmp/llama_pretrain/pytorch_model-00030-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00009-of-00033.bin /tmp/llama_pretrain/pytorch_model-00009-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00002-of-00033.bin /tmp/llama_pretrain/pytorch_model-00002-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00019-of-00033.bin /tmp/llama_pretrain/pytorch_model-00019-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00005-of-00033.bin /tmp/llama_pretrain/pytorch_model-00005-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00022-of-00033.bin /tmp/llama_pretrain/pytorch_model-00022-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00010-of-00033.bin /tmp/llama_pretrain/pytorch_model-00010-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00017-of-00033.bin /tmp/llama_pretrain/pytorch_model-00017-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00033-of-00033.bin /tmp/llama_pretrain/pytorch_model-00033-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:cp s3://llm-artifacts-us-east-1/decapoda-research-llama-7b-hf/pytorch_model-00012-of-00033.bin /tmp/llama_pretrain/pytorch_model-00012-of-00033.bin\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizerFast(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:--DD-- smp.model_creation\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizerFast(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:--DD-- smp.model_creation\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:FK.models.llama:gradient_checkpointing: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:FK.models.llama:gradient_checkpointing: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizerFast(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:--DD-- smp.model_creation\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:FK.models.llama:gradient_checkpointing: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizerFast(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:--DD-- smp.model_creation\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:FK.models.llama:gradient_checkpointing: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizerFast(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:--DD-- smp.model_creation\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:FK.models.llama:gradient_checkpointing: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:   3%|▎         | 1/33 [00:00<00:22,  1.43it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizerFast(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:--DD-- smp.model_creation\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:   3%|▎         | 1/33 [00:00<00:23,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:FK.models.llama:gradient_checkpointing: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:   3%|▎         | 1/33 [00:00<00:21,  1.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:   3%|▎         | 1/33 [00:00<00:23,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:   3%|▎         | 1/33 [00:00<00:22,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:   6%|▌         | 2/33 [00:01<00:21,  1.42it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:   6%|▌         | 2/33 [00:01<00:22,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:   3%|▎         | 1/33 [00:00<00:22,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:   6%|▌         | 2/33 [00:01<00:20,  1.51it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:   6%|▌         | 2/33 [00:01<00:22,  1.35it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:   6%|▌         | 2/33 [00:01<00:22,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:   9%|▉         | 3/33 [00:02<00:21,  1.41it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:   9%|▉         | 3/33 [00:02<00:22,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:   6%|▌         | 2/33 [00:01<00:22,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:   9%|▉         | 3/33 [00:01<00:19,  1.51it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:   9%|▉         | 3/33 [00:02<00:22,  1.35it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:   9%|▉         | 3/33 [00:02<00:21,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizerFast(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:--DD-- smp.model_creation\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  12%|█▏        | 4/33 [00:02<00:20,  1.41it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:FK.models.llama:gradient_checkpointing: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  12%|█▏        | 4/33 [00:02<00:21,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:   9%|▉         | 3/33 [00:02<00:21,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  12%|█▏        | 4/33 [00:02<00:19,  1.51it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  12%|█▏        | 4/33 [00:02<00:21,  1.35it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  12%|█▏        | 4/33 [00:02<00:20,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  15%|█▌        | 5/33 [00:03<00:19,  1.41it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:   3%|▎         | 1/33 [00:00<00:23,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  15%|█▌        | 5/33 [00:03<00:18,  1.51it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  15%|█▌        | 5/33 [00:03<00:20,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  12%|█▏        | 4/33 [00:02<00:20,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  15%|█▌        | 5/33 [00:03<00:20,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  18%|█▊        | 6/33 [00:04<00:19,  1.41it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  15%|█▌        | 5/33 [00:03<00:20,  1.35it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:   6%|▌         | 2/33 [00:01<00:22,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  18%|█▊        | 6/33 [00:03<00:18,  1.49it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  15%|█▌        | 5/33 [00:03<00:20,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  18%|█▊        | 6/33 [00:04<00:20,  1.35it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  21%|██        | 7/33 [00:04<00:18,  1.41it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  18%|█▊        | 6/33 [00:04<00:19,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  18%|█▊        | 6/33 [00:04<00:19,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  21%|██        | 7/33 [00:04<00:17,  1.48it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:   9%|▉         | 3/33 [00:02<00:21,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  18%|█▊        | 6/33 [00:04<00:19,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  21%|██        | 7/33 [00:05<00:19,  1.35it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  24%|██▍       | 8/33 [00:05<00:17,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  21%|██        | 7/33 [00:05<00:18,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  21%|██        | 7/33 [00:05<00:19,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  24%|██▍       | 8/33 [00:05<00:16,  1.48it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  12%|█▏        | 4/33 [00:02<00:20,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  21%|██        | 7/33 [00:05<00:18,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  24%|██▍       | 8/33 [00:05<00:18,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  27%|██▋       | 9/33 [00:06<00:17,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  24%|██▍       | 8/33 [00:05<00:17,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  24%|██▍       | 8/33 [00:05<00:18,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  27%|██▋       | 9/33 [00:06<00:16,  1.47it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  15%|█▌        | 5/33 [00:03<00:20,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  24%|██▍       | 8/33 [00:05<00:17,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  27%|██▋       | 9/33 [00:06<00:17,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  30%|███       | 10/33 [00:07<00:16,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  27%|██▋       | 9/33 [00:06<00:17,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  30%|███       | 10/33 [00:06<00:15,  1.47it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  27%|██▋       | 9/33 [00:06<00:17,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  18%|█▊        | 6/33 [00:04<00:19,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  27%|██▋       | 9/33 [00:06<00:17,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  30%|███       | 10/33 [00:07<00:17,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  33%|███▎      | 11/33 [00:07<00:14,  1.47it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  33%|███▎      | 11/33 [00:07<00:15,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  30%|███       | 10/33 [00:07<00:16,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  30%|███       | 10/33 [00:07<00:16,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  21%|██        | 7/33 [00:05<00:18,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  30%|███       | 10/33 [00:07<00:16,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  33%|███▎      | 11/33 [00:08<00:16,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  36%|███▋      | 12/33 [00:08<00:14,  1.49it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  33%|███▎      | 11/33 [00:07<00:15,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  36%|███▋      | 12/33 [00:08<00:15,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  33%|███▎      | 11/33 [00:08<00:16,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  24%|██▍       | 8/33 [00:05<00:17,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  33%|███▎      | 11/33 [00:07<00:15,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  36%|███▋      | 12/33 [00:08<00:15,  1.35it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  39%|███▉      | 13/33 [00:08<00:13,  1.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  36%|███▋      | 12/33 [00:08<00:15,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  39%|███▉      | 13/33 [00:09<00:14,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  36%|███▋      | 12/33 [00:08<00:15,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  27%|██▋       | 9/33 [00:06<00:17,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  36%|███▋      | 12/33 [00:08<00:15,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  39%|███▉      | 13/33 [00:09<00:14,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  42%|████▏     | 14/33 [00:09<00:12,  1.52it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  39%|███▉      | 13/33 [00:09<00:14,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  42%|████▏     | 14/33 [00:10<00:13,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  39%|███▉      | 13/33 [00:09<00:14,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  30%|███       | 10/33 [00:07<00:16,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  39%|███▉      | 13/33 [00:09<00:14,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  45%|████▌     | 15/33 [00:10<00:11,  1.53it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  42%|████▏     | 14/33 [00:10<00:13,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  42%|████▏     | 14/33 [00:10<00:13,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  42%|████▏     | 14/33 [00:10<00:13,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  45%|████▌     | 15/33 [00:10<00:13,  1.35it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  33%|███▎      | 11/33 [00:07<00:15,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  42%|████▏     | 14/33 [00:10<00:13,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  48%|████▊     | 16/33 [00:10<00:11,  1.53it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  45%|████▌     | 15/33 [00:11<00:13,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  45%|████▌     | 15/33 [00:10<00:13,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  45%|████▌     | 15/33 [00:10<00:13,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  48%|████▊     | 16/33 [00:11<00:12,  1.35it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  36%|███▋      | 12/33 [00:08<00:15,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  45%|████▌     | 15/33 [00:10<00:12,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  52%|█████▏    | 17/33 [00:11<00:10,  1.53it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  48%|████▊     | 16/33 [00:11<00:12,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  48%|████▊     | 16/33 [00:11<00:12,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  48%|████▊     | 16/33 [00:11<00:12,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  52%|█████▏    | 17/33 [00:12<00:11,  1.35it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  39%|███▉      | 13/33 [00:09<00:14,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  55%|█████▍    | 18/33 [00:11<00:09,  1.53it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  48%|████▊     | 16/33 [00:11<00:12,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  52%|█████▏    | 17/33 [00:12<00:11,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  52%|█████▏    | 17/33 [00:12<00:11,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  52%|█████▏    | 17/33 [00:12<00:11,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  58%|█████▊    | 19/33 [00:12<00:09,  1.53it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  55%|█████▍    | 18/33 [00:13<00:11,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  42%|████▏     | 14/33 [00:10<00:13,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  52%|█████▏    | 17/33 [00:12<00:11,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  55%|█████▍    | 18/33 [00:13<00:10,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  61%|██████    | 20/33 [00:13<00:08,  1.53it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  55%|█████▍    | 18/33 [00:12<00:10,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  55%|█████▍    | 18/33 [00:13<00:10,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  55%|█████▍    | 18/33 [00:12<00:10,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  58%|█████▊    | 19/33 [00:13<00:10,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  45%|████▌     | 15/33 [00:10<00:13,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  58%|█████▊    | 19/33 [00:13<00:10,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  64%|██████▎   | 21/33 [00:13<00:07,  1.53it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  58%|█████▊    | 19/33 [00:13<00:10,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  58%|█████▊    | 19/33 [00:13<00:10,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  58%|█████▊    | 19/33 [00:13<00:10,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  48%|████▊     | 16/33 [00:11<00:12,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  61%|██████    | 20/33 [00:14<00:09,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  61%|██████    | 20/33 [00:14<00:09,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  67%|██████▋   | 22/33 [00:14<00:07,  1.54it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  61%|██████    | 20/33 [00:14<00:09,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  61%|██████    | 20/33 [00:14<00:09,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  61%|██████    | 20/33 [00:14<00:09,  1.40it/s][1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  52%|█████▏    | 17/33 [00:12<00:11,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  64%|██████▎   | 21/33 [00:15<00:08,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  64%|██████▎   | 21/33 [00:15<00:08,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  70%|██████▉   | 23/33 [00:15<00:06,  1.54it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  64%|██████▎   | 21/33 [00:15<00:08,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  64%|██████▎   | 21/33 [00:15<00:08,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  64%|██████▎   | 21/33 [00:15<00:08,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  55%|█████▍    | 18/33 [00:12<00:10,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  67%|██████▋   | 22/33 [00:16<00:08,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  67%|██████▋   | 22/33 [00:16<00:08,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  73%|███████▎  | 24/33 [00:15<00:05,  1.54it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  67%|██████▋   | 22/33 [00:15<00:07,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  67%|██████▋   | 22/33 [00:16<00:07,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  67%|██████▋   | 22/33 [00:15<00:07,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  58%|█████▊    | 19/33 [00:13<00:10,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  70%|██████▉   | 23/33 [00:16<00:07,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  76%|███████▌  | 25/33 [00:16<00:05,  1.54it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  70%|██████▉   | 23/33 [00:16<00:07,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  70%|██████▉   | 23/33 [00:16<00:07,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  70%|██████▉   | 23/33 [00:16<00:07,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  70%|██████▉   | 23/33 [00:16<00:07,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  61%|██████    | 20/33 [00:14<00:09,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  73%|███████▎  | 24/33 [00:17<00:06,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  79%|███████▉  | 26/33 [00:17<00:04,  1.54it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  73%|███████▎  | 24/33 [00:17<00:06,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  73%|███████▎  | 24/33 [00:17<00:06,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  73%|███████▎  | 24/33 [00:17<00:06,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  64%|██████▎   | 21/33 [00:15<00:08,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  73%|███████▎  | 24/33 [00:17<00:06,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  82%|████████▏ | 27/33 [00:17<00:03,  1.54it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  76%|███████▌  | 25/33 [00:18<00:05,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  76%|███████▌  | 25/33 [00:18<00:05,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizerFast(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:--DD-- smp.model_creation\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  76%|███████▌  | 25/33 [00:18<00:05,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  76%|███████▌  | 25/33 [00:18<00:05,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:FK.models.llama:gradient_checkpointing: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  67%|██████▋   | 22/33 [00:15<00:07,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  76%|███████▌  | 25/33 [00:17<00:05,  1.40it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  85%|████████▍ | 28/33 [00:18<00:03,  1.53it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  79%|███████▉  | 26/33 [00:19<00:05,  1.34it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  79%|███████▉  | 26/33 [00:19<00:05,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  79%|███████▉  | 26/33 [00:18<00:05,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  79%|███████▉  | 26/33 [00:18<00:05,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  70%|██████▉   | 23/33 [00:16<00:07,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  79%|███████▉  | 26/33 [00:18<00:05,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:   3%|▎         | 1/33 [00:00<00:22,  1.42it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  88%|████████▊ | 29/33 [00:19<00:02,  1.52it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  82%|████████▏ | 27/33 [00:19<00:04,  1.33it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  82%|████████▏ | 27/33 [00:19<00:04,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  91%|█████████ | 30/33 [00:19<00:01,  1.51it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:   6%|▌         | 2/33 [00:01<00:21,  1.44it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  82%|████████▏ | 27/33 [00:19<00:04,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  82%|████████▏ | 27/33 [00:19<00:04,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  73%|███████▎  | 24/33 [00:17<00:06,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  82%|████████▏ | 27/33 [00:19<00:04,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  85%|████████▍ | 28/33 [00:20<00:03,  1.33it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  85%|████████▍ | 28/33 [00:20<00:03,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  94%|█████████▍| 31/33 [00:20<00:01,  1.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:   9%|▉         | 3/33 [00:02<00:20,  1.45it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  85%|████████▍ | 28/33 [00:20<00:03,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  85%|████████▍ | 28/33 [00:20<00:03,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  76%|███████▌  | 25/33 [00:18<00:05,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  85%|████████▍ | 28/33 [00:20<00:03,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  88%|████████▊ | 29/33 [00:21<00:03,  1.33it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  88%|████████▊ | 29/33 [00:21<00:02,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards:  97%|█████████▋| 32/33 [00:21<00:00,  1.49it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  12%|█▏        | 4/33 [00:02<00:19,  1.45it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  88%|████████▊ | 29/33 [00:21<00:02,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  88%|████████▊ | 29/33 [00:21<00:02,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  79%|███████▉  | 26/33 [00:18<00:05,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  88%|████████▊ | 29/33 [00:20<00:02,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  91%|█████████ | 30/33 [00:22<00:02,  1.33it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  91%|█████████ | 30/33 [00:22<00:02,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  15%|█▌        | 5/33 [00:03<00:19,  1.45it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:21<00:00,  1.39it/s][1,mpirank:7,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:21<00:00,  1.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  91%|█████████ | 30/33 [00:21<00:02,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  91%|█████████ | 30/33 [00:21<00:02,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  82%|████████▏ | 27/33 [00:19<00:04,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  91%|█████████ | 30/33 [00:21<00:02,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  94%|█████████▍| 31/33 [00:22<00:01,  1.33it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  94%|█████████▍| 31/33 [00:22<00:01,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  18%|█▊        | 6/33 [00:04<00:18,  1.47it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  94%|█████████▍| 31/33 [00:22<00:01,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  85%|████████▍ | 28/33 [00:20<00:03,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  94%|█████████▍| 31/33 [00:22<00:01,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  94%|█████████▍| 31/33 [00:22<00:01,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards:  97%|█████████▋| 32/33 [00:23<00:00,  1.33it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards:  97%|█████████▋| 32/33 [00:23<00:00,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  21%|██        | 7/33 [00:04<00:17,  1.48it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards:  97%|█████████▋| 32/33 [00:22<00:00,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  88%|████████▊ | 29/33 [00:20<00:02,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards:  97%|█████████▋| 32/33 [00:23<00:00,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards:  97%|█████████▋| 32/33 [00:23<00:00,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  24%|██▍       | 8/33 [00:05<00:16,  1.48it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:24<00:00,  1.25it/s][1,mpirank:5,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:24<00:00,  1.35it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:24<00:00,  1.27it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:24<00:00,  1.35it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  91%|█████████ | 30/33 [00:21<00:02,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:23<00:00,  1.31it/s][1,mpirank:0,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:23<00:00,  1.38it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:24<00:00,  1.29it/s][1,mpirank:3,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:24<00:00,  1.36it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:24<00:00,  1.29it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:24<00:00,  1.37it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  27%|██▋       | 9/33 [00:06<00:16,  1.49it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  94%|█████████▍| 31/33 [00:22<00:01,  1.41it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  30%|███       | 10/33 [00:06<00:15,  1.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards:  97%|█████████▋| 32/33 [00:22<00:00,  1.44it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  33%|███▎      | 11/33 [00:07<00:14,  1.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:23<00:00,  1.37it/s][1,mpirank:2,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:23<00:00,  1.39it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  36%|███▋      | 12/33 [00:08<00:13,  1.51it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  39%|███▉      | 13/33 [00:08<00:13,  1.52it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  42%|████▏     | 14/33 [00:09<00:12,  1.54it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  45%|████▌     | 15/33 [00:10<00:11,  1.54it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  48%|████▊     | 16/33 [00:10<00:11,  1.54it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:FK.models.llama:Config pad token id after loading pre-trained weights: 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-05-26 07:54:35.038: I smdistributed/modelparallel/torch/model.py:153] [7] Bit16_Module initialized, using dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-05-26 07:54:35.054: I smdistributed/modelparallel/torch/optimizers/optimizer.py:513] [7] Bit16_Optimizer initialized with dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:--DD-- before main.train() ..\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:-DD- epoch...0.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:-DD- _file.../opt/ml/input/data/train123/.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:-DD- in _load_and_cache_examples, local rank =  7\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  52%|█████▏    | 17/33 [00:11<00:10,  1.54it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  55%|█████▍    | 18/33 [00:11<00:09,  1.55it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  58%|█████▊    | 19/33 [00:12<00:09,  1.55it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:FK.models.llama:Config pad token id after loading pre-trained weights: 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-05-26 07:54:37.097: I smdistributed/modelparallel/torch/model.py:153] [5] Bit16_Module initialized, using dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:FK.models.llama:Config pad token id after loading pre-trained weights: 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-05-26 07:54:37.111: I smdistributed/modelparallel/torch/model.py:153] [4] Bit16_Module initialized, using dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-05-26 07:54:37.112: I smdistributed/modelparallel/torch/optimizers/optimizer.py:513] [5] Bit16_Optimizer initialized with dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:--DD-- before main.train() ..\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:-DD- epoch...0.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:-DD- _file.../opt/ml/input/data/train123/.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:-DD- in _load_and_cache_examples, local rank =  [1,mpirank:5,algo-1]<stdout>:5\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  61%|██████    | 20/33 [00:13<00:08,  1.55it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-05-26 07:54:37.127: I smdistributed/modelparallel/torch/optimizers/optimizer.py:513] [4] Bit16_Optimizer initialized with dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:--DD-- before main.train() ..\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:-DD- epoch...0.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:-DD- _file.../opt/ml/input/data/train123/.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:-DD- in _load_and_cache_examples, local rank =  [1,mpirank:4,algo-1]<stdout>:4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:FK.models.llama:Config pad token id after loading pre-trained weights: 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:37.361: I smdistributed/modelparallel/torch/model.py:153] [0] Bit16_Module initialized, using dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:FK.models.llama:Config pad token id after loading pre-trained weights: 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:37.377: I smdistributed/modelparallel/torch/optimizers/optimizer.py:513] [0] Bit16_Optimizer initialized with dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-05-26 07:54:37.383: I smdistributed/modelparallel/torch/model.py:153] [3] Bit16_Module initialized, using dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:FK.models.llama:Config pad token id after loading pre-trained weights: 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:--DD-- after OmegaConf.save() to training_config.yaml\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:--DD-- before main.train() ..\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:-DD- epoch...0.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:-DD- _file.../opt/ml/input/data/train123/.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:-DD- in _load_and_cache_examples, local rank =  0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-05-26 07:54:37.397: I smdistributed/modelparallel/torch/model.py:153] [1] Bit16_Module initialized, using dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-05-26 07:54:37.399: I smdistributed/modelparallel/torch/optimizers/optimizer.py:513] [3] Bit16_Optimizer initialized with dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:--DD-- before main.train() ..\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:-DD- epoch...0.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:-DD- _file.../opt/ml/input/data/train123/.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:-DD- in _load_and_cache_examples, local rank =  3\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-05-26 07:54:37.413: I smdistributed/modelparallel/torch/optimizers/optimizer.py:513] [1] Bit16_Optimizer initialized with dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:--DD-- before main.train() ..\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:-DD- epoch...0.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:-DD- _file.../opt/ml/input/data/train123/.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:-DD- in _load_and_cache_examples, local rank =  1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:NCCL version 2.16.2+cuda11.8\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  64%|██████▎   | 21/33 [00:13<00:07,  1.56it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  67%|██████▋   | 22/33 [00:14<00:07,  1.54it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  70%|██████▉   | 23/33 [00:15<00:06,  1.53it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:FK.models.llama:Config pad token id after loading pre-trained weights: 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-05-26 07:54:39.372: I smdistributed/modelparallel/torch/model.py:153] [2] Bit16_Module initialized, using dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-05-26 07:54:39.388: I smdistributed/modelparallel/torch/optimizers/optimizer.py:513] [2] Bit16_Optimizer initialized with dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:--DD-- before main.train() ..\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:-DD- epoch...0.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:-DD- _file.../opt/ml/input/data/train123/.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:-DD- in _load_and_cache_examples, local rank =  2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  73%|███████▎  | 24/33 [00:15<00:05,  1.52it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  76%|███████▌  | 25/33 [00:16<00:05,  1.51it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  79%|███████▉  | 26/33 [00:17<00:04,  1.51it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  82%|████████▏ | 27/33 [00:17<00:03,  1.51it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  85%|████████▍ | 28/33 [00:18<00:03,  1.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  88%|████████▊ | 29/33 [00:19<00:02,  1.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  91%|█████████ | 30/33 [00:19<00:01,  1.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  94%|█████████▍| 31/33 [00:20<00:01,  1.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards:  97%|█████████▋| 32/33 [00:21<00:00,  1.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015Loading checkpoint shards: 100%|██████████| 33/33 [00:22<00:00,  1.40it/s]#015Loading checkpoint shards: 100%|██████████| 33/33 [00:22<00:00,  1.50it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:FK.models.llama:Config pad token id after loading pre-trained weights: 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-05-26 07:54:53.530: I smdistributed/modelparallel/torch/model.py:153] [6] Bit16_Module initialized, using dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-05-26 07:54:53.547: I smdistributed/modelparallel/torch/optimizers/optimizer.py:513] [6] Bit16_Optimizer initialized with dtype torch.bfloat16\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:--DD-- before main.train() ..\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:-DD- epoch...0.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:-DD- _file.../opt/ml/input/data/train123/.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:-DD- in _load_and_cache_examples, local rank =  6\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loading data from /opt/ml/input/data/train123/human_value_alignment_instructions_part1_new.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loading data from /opt/ml/input/data/train123/human_value_alignment_instructions_part1_new.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loading data from /opt/ml/input/data/train123/human_value_alignment_instructions_part1_new.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loading data from /opt/ml/input/data/train123/human_value_alignment_instructions_part1_new.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loading data from /opt/ml/input/data/train123/human_value_alignment_instructions_part1_new.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loading data from /opt/ml/input/data/train123/human_value_alignment_instructions_part1_new.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loading data from /opt/ml/input/data/train123/human_value_alignment_instructions_part1_new.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loading data from /opt/ml/input/data/train123/human_value_alignment_instructions_part1_new.json\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:-DD- sub_train_dataset return rank : 1...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:-DD- sub_train_dataset return rank : 0...\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:-DD- sub_train_dataset return rank : 7...\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:-DD- sub_train_dataset return rank : 3...\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:-DD- sub_train_dataset return rank : 2...\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:-DD- sub_train_dataset return rank : 6...\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:FK.ZN_INSTRUCT:Loaded 2998 examples.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:-DD- sub_train_dataset return rank : 5...\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:-DD- sub_train_dataset return rank : 4...\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizer(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizer(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizer(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizer(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizer(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizer(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015Iteration:   0%|          | 0/374 [00:00<?, ?it/s]#033[A[1,mpirank:3,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizer(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:Using pad_token, but it is not set yet.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:LlamaTokenizer(name_or_path='/tmp/llama_pretrain', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '[PAD]'}, clean_up_tokenization_spaces=False)\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:FK.general_util.tokenization_utils:PAD TOKEN ID = 32000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:--DD-- before batch_to_device - cuda:6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:--DD-- before batch_to_device - cuda:7\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:--DD-- before batch_to_device - cuda:1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:--DD-- before batch_to_device - cuda:2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:--DD-- before batch_to_device - cuda:0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:--DD-- before batch_to_device - cuda:3\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:55.573: I smdistributed/modelparallel/torch/worker.py:300] Tracing on GPU. If the model parameters do not fit in a single GPU, you can set trace_device to `cpu`.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:--DD-- before batch_to_device - cuda:5\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:--DD-- before batch_to_device - cuda:4\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.028: I smdistributed/modelparallel/torch/model.py:665] Partition assignments:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/lm_head: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/embed_tokens: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/norm: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/0: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/1: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/2: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/3: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/4: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/5: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/6: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/7: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.029: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/8: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/9: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/10: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/11: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/12: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/13: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/14: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/15: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/16: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/17: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/18: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/19: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/20: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/21: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/22: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/23: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/24: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/25: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/26: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.030: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/27: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.031: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/28: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.031: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/29: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.031: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/30: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:54:59.031: I smdistributed/modelparallel/torch/model.py:674] main/module/module/module/model/layers/31: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-05-26 07:54:59.448: I smdistributed/modelparallel/torch/model.py:599] Number of parameters on partition 7 are 36. 36 require grads\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-05-26 07:54:59.449: I smdistributed/modelparallel/torch/model.py:599] Number of parameters on partition 6 are 36. 36 require grads\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-05-26 07:54:59.449: I smdistributed/modelparallel/torch/model.py:628] Number of buffers on partition 7 are 12.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-05-26 07:54:59.450: I smdistributed/modelparallel/torch/model.py:628] Number of buffers on partition 6 are 12.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-05-26 07:54:59.466: I smdistributed/modelparallel/torch/model.py:599] Number of parameters on partition 3 are 36. 36 require grads\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-05-26 07:54:59.467: I smdistributed/modelparallel/torch/model.py:628] Number of buffers on partition 3 are 12.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-05-26 07:54:59.478: I smdistributed/modelparallel/torch/model.py:599] Number of parameters on partition 2 are 36. 36 require grads\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-05-26 07:54:59.479: I smdistributed/modelparallel/torch/model.py:628] Number of buffers on partition 2 are 12.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-05-26 07:54:59.488: I smdistributed/modelparallel/torch/model.py:599] Number of parameters on partition 5 are 36. 36 require grads\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-05-26 07:54:59.490: I smdistributed/modelparallel/torch/model.py:628] Number of buffers on partition 5 are 12.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-05-26 07:54:59.493: I smdistributed/modelparallel/torch/model.py:599] Number of parameters on partition 4 are 36. 36 require grads\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-05-26 07:54:59.494: I smdistributed/modelparallel/torch/model.py:628] Number of buffers on partition 4 are 12.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-05-26 07:54:59.588: I smdistributed/modelparallel/torch/model.py:599] Number of parameters on partition 1 are 45. 45 require grads\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-05-26 07:54:59.590: I smdistributed/modelparallel/torch/model.py:628] Number of buffers on partition 1 are 15.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:55:07.207: I smdistributed/modelparallel/torch/model.py:599] Number of parameters on partition 0 are 30. 30 require grads\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:55:07.208: I smdistributed/modelparallel/torch/model.py:628] Number of buffers on partition 0 are 9.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-05-26 07:55:07.851: I smdistributed/modelparallel/torch/model.py:725] Finished partitioning the model\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:NCCL version 2.16.2+cuda11.8\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:NCCL version 2.16.2+cuda11.8\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:NCCL version 2.16.2+cuda11.8\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:NCCL version 2.16.2+cuda11.8\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:NCCL version 2.16.2+cuda11.8\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:NCCL version 2.16.2+cuda11.8\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:NCCL version 2.16.2+cuda11.8\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:--DD-- In @smp.step loss is 10.8125\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# change to fp16=false, TBD: 1/model creation without wrapper; 2/no barrier in cache data\n",
    "dat_chnl = {'train123':'s3://llm-artifacts-us-east-1/datasets/coig/'}\n",
    "est.fit(dat_chnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bcce0b-1a02-4821-9838-42d196d34120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c2dfb-9de6-40ac-9754-b167f8027e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42db27f-47a9-4db9-80ae-898ce8bb39ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
